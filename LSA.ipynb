{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99ab5c88",
   "metadata": {},
   "source": [
    "# Eksempel på koder vi har kjørt for å teste ut vårt semantiske rom:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfd6247",
   "metadata": {},
   "source": [
    "\n",
    "#!/usr/bin/env python3\n",
    " -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Oct 25 12:29:21 2022\n",
    " \n",
    "@author: ketil\n",
    "\"\"\"\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d13fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mange pakker nødvendig, også for nltk\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "nltk.download('punkt')\n",
    "from sklearn.manifold import TSNE\n",
    "import random\n",
    "#%%\n",
    " \n",
    "#%%\n",
    "import os\n",
    "os.getcwd()\n",
    "os.chdir('/Users/ketil/Documents/Programming tools and tests/Gensim codes')\n",
    "#%%\n",
    "  \n",
    "#%%\n",
    "#Importerer datasett fra Github og lagrer det lokalt\n",
    "import requests\n",
    " \n",
    "url = 'https://raw.githubusercontent.com/robinjansson/puls-r_forskningsprosjekt/d6a33a5ba29508ad36bd14785e0a8b591aa38849/norsk_aviskorpus_clean_nps_10k.csv?token=GHSAT0AAAAAAB2CTZPXO27NU536IITV2YWAY2Y54LQ'\n",
    "r = requests.get(url, allow_redirects=True)\n",
    " \n",
    "open('data.csv', 'wb').write(r.content)\n",
    "#%%\n",
    " \n",
    "#%%\n",
    "df = pd.read_csv('norsk_aviskorpus_clean_nps.csv', delimiter='/n')\n",
    " \n",
    "#%%\n",
    " \n",
    "#%%\n",
    "df.Article.head(10)\n",
    "articles = df.Article.values\n",
    "print(f'{len(articles):,}')\n",
    "#%%\n",
    " \n",
    "#%%\n",
    "articles[1003]\n",
    " \n",
    "#%%\n",
    " \n",
    "#%%\n",
    "articleVec = [nltk.word_tokenize(Article) for Article in articles]\n",
    "#%%\n",
    " \n",
    "#%%\n",
    "#Check if the tokenization worked\n",
    "articleVec[6]\n",
    "#%%\n",
    " \n",
    "#%%\n",
    "#Bestemmer lengden på ord-databasen:\n",
    "training_words = []\n",
    "for i in range (len(articleVec)):\n",
    "    training_words.append(len(articleVec[i]))\n",
    " \n",
    "print(f'Antall tokens: {sum(training_words):,}')\n",
    "print(f'Gjennomsnittlig dokumentlengde: {sum(training_words) / len(articles):,.0f}')\n",
    "#%%\n",
    " \n",
    "#%%\n",
    "#Trener Word2Vec-modell, dvs modell:\n",
    "    model = Word2Vec(articleVec, vector_size=100, workers=4)\n",
    "    model.wv[0]\n",
    "    model.save(\"word2vec_model_NoAv_TEST_vs100\")\n",
    "#%%\n",
    " \n",
    "#%%\n",
    "#Henter ut alle ordene fra det semantiske rommet (model.wv.index_to_key)\n",
    "sr_words = model.wv.index_to_key\n",
    "print(f'Antall ord i semantisk rom: {len(sr_words):,}')\n",
    "#%%\n",
    " \n",
    "#%%\n",
    "# Henter ut alle vektorene i det semantiske rommet\n",
    "sr_vectors = model.wv.vectors\n",
    "print(f'Antall vektorer i semantisk rom: {len(sr_vectors):,}')\n",
    "#%%\n",
    " \n",
    "#%%\n",
    "#Finner \"word count\" for for definert ord\n",
    "model.wv.get_vecattr('test', 'count')\n",
    "#%%\n",
    " \n",
    "#%%\n",
    "#Hyppigste og sjeldneste ord:\n",
    "    #Først en ordtelling:\n",
    "word_count = []\n",
    "for i in range(len(sr_words)):\n",
    "    count = model.wv.get_vecattr(sr_words[i], 'count')\n",
    "    word_count.append(count)    \n",
    "#%%\n",
    " \n",
    "#%%\n",
    "#Deretter de 20 hyppigste ord:\n",
    "def word_count_top(num):\n",
    "    top_words = sr_words[0:num]\n",
    "    top_count = word_count[0:num]\n",
    "    \n",
    "    for i in range(len(top_words)):\n",
    "        print(f'{top_words[i]}: {top_count[i]}')\n",
    "        \n",
    "word_count_top(20)\n",
    "#%%\n",
    " \n",
    "#%%\n",
    "#Detter de minst frekvente ordene:\n",
    "def word_count_low(num):\n",
    "    low_words = sr_words[-num:]\n",
    "    low_count = word_count[-num:]\n",
    "    \n",
    "    for i in range(len(low_words)):\n",
    "        print(f'{low_words[i]}: {low_count[i]}')\n",
    "        \n",
    "word_count_low(20)    \n",
    "#%%\n",
    " \n",
    "#%%\n",
    "#Visualisering av \"word count\" for alle ord i semantisk rom\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "plt.plot(word_count)\n",
    "plt.show()\n",
    "#%%\n",
    " \n",
    "#%%\n",
    "#Visualisering av \"word count\" for top 500 ord i semantisk rom\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "plt.plot(word_count[0:300])\n",
    "plt.show()\n",
    "#%%\n",
    " \n",
    "#%%\n",
    "#Antall ord over / under et definert \"word count\"\n",
    "def word_count_num(num):\n",
    "    below_count = 0\n",
    "    for i in range(len(word_count)):\n",
    "        if word_count[i] < num:\n",
    "            below_count += 1\n",
    "    above_count = len(sr_words) - below_count\n",
    " \n",
    "    print('Above {}: {}'.format(num, above_count))\n",
    "    print('Below {}: {}'.format(num, below_count))\n",
    " \n",
    "word_count_num(10) #definer \"word count\"\n",
    "#%%\n",
    " \n",
    "#%%\n",
    "#Top x \"most similar\" ord til et definert ord\n",
    "model.wv.most_similar('overrasket', topn=10)\n",
    " \n",
    "#%%\n",
    " \n",
    "#%%\n",
    "#Tweak for å hente ut hele listen med \"most similar\" (topn=sys.maxsize)\n",
    "import sys\n",
    "all_sims = model.wv.most_similar('angst', topn=sys.maxsize)\n",
    "len(all_sims)\n",
    " \n",
    "all_sims[0]\n",
    "#%%\n",
    " \n",
    "#%%\n",
    "#Funksjon for å beregne \"least similar\" \n",
    "def least_similar(word, lastn=5):\n",
    "    all_sims = model.wv.most_similar(word, topn=sys.maxsize)\n",
    "    least_sim = list(reversed(all_sims[-lastn:]))\n",
    "    return least_sim\n",
    " \n",
    "least_similar('angst', lastn=10)\n",
    " \n",
    " \n",
    "#%%\n",
    " \n",
    "#%%\n",
    "#model.wv.similarity\n",
    "model.wv.similarity('positiv', 'negativ')\n",
    " \n",
    "#%%\n",
    " \n",
    "#%%\n",
    "#Funksjon for å beregne \"cosine similarity\" fra scratch\n",
    " \n",
    "def cosine_similarity(word_1, word_2):\n",
    "    \n",
    "    for i in range(len(sr_words)):\n",
    "        if sr_words[i] == word_1:\n",
    "            v1 = sr_vectors[i]\n",
    "        if sr_words[i] == word_2:\n",
    "            v2 = sr_vectors[i]\n",
    "    \n",
    "    v1_norm = v1 / np.linalg.norm(v1)\n",
    "    v2_norm = v2 / np.linalg.norm(v2)\n",
    "    \n",
    "    cos_sim = np.dot(v1_norm, v2_norm)\n",
    "    \n",
    "    return cos_sim  \n",
    " \n",
    "cosine_similarity('positiv', 'negativ')\n",
    "#%%\n",
    " \n",
    "#%%\n",
    "#model.wv.doesnt_match\n",
    "#Ord som passer minst inn blant en liste med ord:@\n",
    "testlist = ['angst', 'depresjon', 'søvnløshet', 'smile']\n",
    "model.wv.doesnt_match(testlist)\n",
    " \n",
    "#%%\n",
    " \n",
    "#%%\n",
    "#Eksempel med en hel fasett\n",
    "con = sqlite3.connect('analysebibliotek.db')\n",
    "cur = con.cursor()\n",
    "cur.execute('''SELECT WORD FROM Norsk_Database_V3 WHERE lower(FACET)=?;''',('tillit', ))\n",
    "f = cur.fetchall()\n",
    "con.commit()\n",
    "con.close()\n",
    " \n",
    "facet = []\n",
    "for i in range(len(f)):\n",
    "    facet.append(f[i][0].lower())\n",
    " \n",
    "#%%\n",
    " \n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
